{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ch4: Manipulating Tensors\n",
        "Optimizing tensor operations is very important when dealing with large amounts of complex data."
      ],
      "metadata": {
        "id": "K4aupX7IdWHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSOKltcpduNW",
        "outputId": "7a2bb709-1ef7-4e32-cb6a-919bed9633cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations"
      ],
      "metadata": {
        "id": "EgDq1TRmdbL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing & Slicing\n",
        "Indexing and slicing are the exact same as NumPy `ndarray`s. If we want to get the Python value, we call `tensor.item()`."
      ],
      "metadata": {
        "id": "_OTuPspwgAk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_dim_tensor = torch.tensor([1,2,3,4,5,6,7,8])\n",
        "print(one_dim_tensor[2])\n",
        "print(one_dim_tensor[2].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXBsYO5fdceS",
        "outputId": "5d4fb29a-d020-45de-9215-7178bc5758ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing follows the following syntax: `[start:end:step]` (`start` inclusive, `end` exclusive)"
      ],
      "metadata": {
        "id": "V01VJTEbe18X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_dim_tensor[1:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDVg6uXoeQww",
        "outputId": "670e8559-f760-4011-e3de-328b66b4d4cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a 2D example."
      ],
      "metadata": {
        "id": "axVLDwZOeOlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_dim_tensor = torch.tensor([\n",
        "    [1,2,3,4,5,6],\n",
        "    [7,8,9,10,11,12],\n",
        "    [13,14,15,16,17,18],\n",
        "    [19,20,21,22,23,24]\n",
        "])\n",
        "\n",
        "two_dim_tensor[1][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To1B8b3mehX-",
        "outputId": "cdde5395-9792-48e9-8b28-bbc720db4df9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"first 3 elements of 1st row: \", two_dim_tensor[0, 0:3])\n",
        "print(\"first 4 elements of 2nd row: \", two_dim_tensor[1,0:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOCB4PpAezei",
        "outputId": "2f9fa592-211c-4935-a2da-3dc712ce4b36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 3 elements of 1st row:  tensor([1, 2, 3])\n",
            "first 4 elements of 2nd row:  tensor([ 7,  8,  9, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also index with criteria."
      ],
      "metadata": {
        "id": "mUzV0a_ufH4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_dim_tensor[two_dim_tensor<11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyNCBZl_fHUU",
        "outputId": "d44c68ef-1e0c-4500-d6af-9bf460324eb6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining & Splitting"
      ],
      "metadata": {
        "id": "XeMCUJRUgE3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To combine tensors, we can use `torch.stack()`."
      ],
      "metadata": {
        "id": "pCmsOknafPYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack((two_dim_tensor, two_dim_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD5WT14CfR4y",
        "outputId": "327e9ec0-edfa-4361-fd52-3fd0f51ec49b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4,  5,  6],\n",
              "         [ 7,  8,  9, 10, 11, 12],\n",
              "         [13, 14, 15, 16, 17, 18],\n",
              "         [19, 20, 21, 22, 23, 24]],\n",
              "\n",
              "        [[ 1,  2,  3,  4,  5,  6],\n",
              "         [ 7,  8,  9, 10, 11, 12],\n",
              "         [13, 14, 15, 16, 17, 18],\n",
              "         [19, 20, 21, 22, 23, 24]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To split tensors, we use `torch.unbind()`."
      ],
      "metadata": {
        "id": "Vguj7mqSfVvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unbind(two_dim_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4DMlKGrfYuQ",
        "outputId": "be0ac663-a820-4876-dcd9-78ed54cb149f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]),\n",
              " tensor([ 7,  8,  9, 10, 11, 12]),\n",
              " tensor([13, 14, 15, 16, 17, 18]),\n",
              " tensor([19, 20, 21, 22, 23, 24]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, PyTorch splits by row. We can use `dim=1` to split by column instead."
      ],
      "metadata": {
        "id": "ML2Fm_l5fZ3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unbind(two_dim_tensor,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0zp6nY6fiXz",
        "outputId": "db7246ee-679c-4eb6-88df-bc90a9145924"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  7, 13, 19]),\n",
              " tensor([ 2,  8, 14, 20]),\n",
              " tensor([ 3,  9, 15, 21]),\n",
              " tensor([ 4, 10, 16, 22]),\n",
              " tensor([ 5, 11, 17, 23]),\n",
              " tensor([ 6, 12, 18, 24]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math Functions\n",
        "PyTorch has a lot of built-in math expressions.\n",
        "\n",
        "**Pointwise operations** (aka element-wise operations) perform on each individual element and then return the new tensor.\n",
        "- Math functions\n",
        "- Truncation\n",
        "- Logical functions\n",
        "- Trig functions\n",
        "\n",
        "**Reduction operations** reduces the dimensionality or rank of a tensor.\n",
        "- Statistical functions like mean or mode\n",
        "\n",
        "**Comparison functions** compares values within a tensor or between 2 tensors\n",
        "- Min/max values\n",
        "- Sort values\n",
        "- Test tensor status or conditions\n",
        "\n",
        "**Linear algebra** enables matrix opeations\n",
        "- Essential for deep-learning computations\n",
        "- Matrix and tensor computations\n",
        "\n",
        "\n",
        "**Spectral** and other math functions are useful for data transformation and analysis"
      ],
      "metadata": {
        "id": "u73nDK0IfyxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Pointwise Functions"
      ],
      "metadata": {
        "id": "9kStBGsEsMya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([10,2,8,6,4])\n",
        "b = torch.tensor([1,2,4,3,1])\n",
        "print('a+b:', a.add(b))\n",
        "print('a*b', a.mul(b))\n",
        "print('a/b:', a.div(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CPUHQcLqL3v",
        "outputId": "b34a01c1-277f-482c-9d5f-b76a7a937901"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a+b: tensor([11,  4, 12,  9,  5])\n",
            "a*b tensor([10,  4, 32, 18,  4])\n",
            "a/b: tensor([10.,  1.,  2.,  2.,  4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Reduction Functions\n",
        "Note that we have to use floating point numbers because `mean()` and `std()` only work with floating points."
      ],
      "metadata": {
        "id": "O3TImwKosQDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.tensor([[20, 14, 11, 8], [3, 19, 14, 6]], dtype=torch.float)\n",
        "print('Mean:', torch.mean(c))\n",
        "print('Median:', torch.median(c))\n",
        "print('Mode:', torch.mode(c))\n",
        "print('Std:', torch.std(c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG9Pn23MqvI8",
        "outputId": "3ed0e203-37cd-423f-ad64-40501003a50b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor(11.8750)\n",
            "Median: tensor(11.)\n",
            "Mode: torch.return_types.mode(\n",
            "values=tensor([8., 3.]),\n",
            "indices=tensor([3, 0]))\n",
            "Std: tensor(6.0341)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Algebra\n",
        "PyTorch has a module called `torch.linalg` that contains lots of useful linear algebra functions. These functions are the same as NumPy, but with the added functionalities of tensors.\n",
        "\n",
        "We can use `torch.matmul()` for multiplication between any dimension tensors. 2 vectors will result in the scalar dot product."
      ],
      "metadata": {
        "id": "T05U_01lraZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product\n",
        "first_tensor = torch.tensor([1,2,3])\n",
        "second_tensor = torch.tensor([4,5,6])\n",
        "\n",
        "dot_product = torch.matmul(first_tensor,second_tensor)\n",
        "dot_product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plyzhGAerodC",
        "outputId": "fe7927fc-3270-4b1e-b6fb-e9cbbe0b2a95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication\n",
        "first_2d_tensor = torch.tensor([[1,2,3],[-1,-2,-3]])\n",
        "second_2d_tensor = torch.tensor([[-1,-2],[4,5],[4,5]])\n",
        "\n",
        "result_2d_tensor = torch.matmul(first_2d_tensor, second_2d_tensor)\n",
        "result_2d_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jg7G1zrtQmT",
        "outputId": "af0f863f-79a9-405b-fdbc-0c97e8642a2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 19,  23],\n",
              "        [-19, -23]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use `torch.mm()` which is a lot faster, but it only supports 2D tensors and doesn't support broadcasting.\n",
        "\n",
        "`multi_dot()` can chain multiple matrix multiplications together, which is very useful for deep learning NNs."
      ],
      "metadata": {
        "id": "i0yH-5p4vEFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chained matrix multiplication\n",
        "first_ten = torch.randn(2, 3)\n",
        "second_ten = torch.randn(3, 4)\n",
        "third_ten = torch.randn(4, 5)\n",
        "fourth_ten = torch.randn(5, 6)\n",
        "fifth_ten = torch.randn(6, 7)\n",
        "\n",
        "torch.linalg.multi_dot((first_ten,second_ten,third_ten,fourth_ten,fifth_ten))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zaH-n3ktWWO",
        "outputId": "be02c8a9-24d9-4e3b-8181-7c97992e7424"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-31.8836,   6.7960,   5.1101, -11.6770,  15.1170,  -8.0794,  -4.2135],\n",
              "        [ -5.6098,  -7.4835,   9.1502,  16.5956, -14.7858,  -2.0040,  11.1746]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Differentiation (Autograd)\n",
        "PyTorch automatically performs automatic differentiation for all tensor operations. This is very helpful for back propogation. Furthermore, we can view the individual gradients with the `grad` attribute."
      ],
      "metadata": {
        "id": "KGJJNiZNvbFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.autograd.Variable(torch.Tensor([2]), requires_grad=True)\n",
        "y = torch.autograd.Variable(torch.Tensor([1]), requires_grad=True)\n",
        "z = torch.autograd.Variable(torch.Tensor([5]), requires_grad=True)\n",
        "\n",
        "# forward prop\n",
        "a = x - y\n",
        "f = z * a\n",
        "print(f'f = {f}')\n",
        "\n",
        "# backward prop\n",
        "f.backward()\n",
        "\n",
        "print('Gradient value for x:', x.grad)\n",
        "print('Gradient value for y:', y.grad)\n",
        "print('Gradient value for z:', z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpz2dPv4xD75",
        "outputId": "53660e35-08e6-4665-ee2a-50255cbf5f06"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f = tensor([5.], grad_fn=<MulBackward0>)\n",
            "Gradient value for x: tensor([5.])\n",
            "Gradient value for y: tensor([-5.])\n",
            "Gradient value for z: tensor([1.])\n"
          ]
        }
      ]
    }
  ]
}