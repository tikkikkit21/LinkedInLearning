{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWfWFm2edyMG"
      },
      "source": [
        "# Tabular Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lDPHYy1jDVe"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4TSFfeDEUhs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Normalization, StringLookup, CategoryEncoding, IntegerLookup\n",
        "pd.set_option('display.max_rows', 10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBRqQw_sV2YD"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26BrsMaPEbdQ",
        "outputId": "687fdc0f-9c70-409d-e34a-cfac6d98b4ae"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
        "TEST_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/eval.csv'\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file('train.csv', TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file('eval.csv', TEST_DATA_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y9QB00VjsZT"
      },
      "source": [
        "## Prepare & Analyze Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1kd4abU9pG"
      },
      "source": [
        "### Train/Val/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doSO6pCAFQ7a"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(train_file_path)\n",
        "test = pd.read_csv(test_file_path)\n",
        "\n",
        "test, val = train_test_split(test, test_size=0.5)\n",
        "\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlmYgG26enYS"
      },
      "source": [
        "### Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "f0PevNpGqc8j",
        "outputId": "4739f834-9760-48b3-8a5f-97a9fe1ccb34"
      },
      "outputs": [],
      "source": [
        "train.age.hist(bins=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "g-8LsJrsrDwu",
        "outputId": "6f13a461-7f61-447b-9e63-d81a82f8c248"
      },
      "outputs": [],
      "source": [
        "train.sex.value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vwqldTMArIs7",
        "outputId": "f1078aca-24e4-4473-e3db-3ec41b635365"
      },
      "outputs": [],
      "source": [
        "train['class'].value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XcvcR5MBrRJC",
        "outputId": "8462e562-3f62-4685-ac43-3f2344bbec72"
      },
      "outputs": [],
      "source": [
        "train.groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "ukAk51aLs_nS",
        "outputId": "0160185c-ab42-45c8-ec43-4f864f7fbd7c"
      },
      "outputs": [],
      "source": [
        "train[(train.age < 18) & (train['class'] == 'First')].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_7uVu-xyEqv"
      },
      "source": [
        "## `tf.data` API\n",
        "- TensorFlow 2.0 documentation\n",
        "    - [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
        "    - [tf.data.Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices)\n",
        "- This helper function will:\n",
        "    - Remove label feature\n",
        "    - Convert DataFrame to Tensor dataset\n",
        "    - Shuffle and batch records\n",
        "- Using `prefetch` lets us prepare the next batch while the model is processing the current batch\n",
        "    - Note that it requires GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDpiOf8dCVIs",
        "outputId": "0707c0c9-aff3-4d5f-d5d5-9c3db6f00ebf"
      },
      "outputs": [],
      "source": [
        "# dataframe = train.copy()\n",
        "\n",
        "# data = tf.data.Dataset.from_tensor_slices((dict(dataframe), dataframe.pop('survived')))\n",
        "# for item in data:\n",
        "#   print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4j-1lRyEqw"
      },
      "outputs": [],
      "source": [
        "def df_to_dataset(df, shuffle=True, batch_size=3):\n",
        "    df = df.copy()\n",
        "    labels = df.pop('survived')\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(df))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYxIXH579uS9"
      },
      "source": [
        "Now that you have created the input pipeline, let's call it to see the format of the data it returns. You have used a small batch size to keep the output readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1sOwjcLX4Pj",
        "outputId": "faf75b8e-6bbe-44be-859c-fb4c3016d059"
      },
      "outputs": [],
      "source": [
        "train_ds = df_to_dataset(train)\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEzAqf5nYKx1",
        "outputId": "1b9cf983-dfa1-483f-e772-521d2b6d1265"
      },
      "outputs": [],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "label_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZFZBaH2nUr"
      },
      "source": [
        "- You can see that we have a batch of 3 passengers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFYir6S8HgIJ",
        "outputId": "50139a7f-df8b-4287-dae0-c4f02bad1b34"
      },
      "outputs": [],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of ages:', train_features['age'])\n",
        "print('A batch of labels:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qny1jxBFpFwH"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twXBSxnT66o8"
      },
      "source": [
        "### Numeric columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "rlsaY02wRSZ6",
        "outputId": "6a4a4e77-c60d-498c-a184-b578d003ba21"
      },
      "outputs": [],
      "source": [
        "train.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OosUh4kTsK_q"
      },
      "source": [
        "Let's create a function `get_normalization_layer` that returns a layer which applies featurewise normalization to numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6OuEKMMyEq1"
      },
      "outputs": [],
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  # Create a Normalization layer for our feature.\n",
        "  normalizer = Normalization(axis=None)\n",
        "\n",
        "  # Prepare a Dataset that only yields our feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # A pre-processing / non-traininable layer. \n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  return normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "287LolNVFXOe"
      },
      "source": [
        "The TensorFlow 2.0 Documentation has more information on the [adapt method](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method) if you want to find out more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tPWogCHa7bf",
        "outputId": "19c364a1-1eab-48a8-fb62-e6891ec0546c"
      },
      "outputs": [],
      "source": [
        "age_column = train_features['age']\n",
        "age_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItY5s86l842d"
      },
      "source": [
        "- You can see that when we pass a batch of 3 numerical ages to the get_normalization_layer, they are returned as normalized features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H0fzmP6bUPb",
        "outputId": "b3f14be3-67f9-438a-fe50-85dc89739c08"
      },
      "outputs": [],
      "source": [
        "numeric_layer = get_normalization_layer('age', train_ds)\n",
        "numeric_layer(age_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVD--2WZ7vmh"
      },
      "source": [
        "### Categorical columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49mT8vyfKNB"
      },
      "source": [
        "In this dataset, the town that passengers embarked is represented as a string (e.g. 'Southampton', 'Cherbourg', 'Queenstown' or 'unknown'). You cannot feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot encoding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqmBUXgneEF1",
        "outputId": "e5dad394-e100-4f95-fd2a-412ab5adad0a"
      },
      "outputs": [],
      "source": [
        "train.embark_town.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWlkOPwMsxdv"
      },
      "source": [
        "`get_category_encoding_layer` function returns a layer which maps values from a vocabulary to integer indices and one-hot encodes the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmgaeRjlDoUO"
      },
      "outputs": [],
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Create a StringLookup layer which will turn strings into integer indices\n",
        "  if dtype == 'string':\n",
        "    index = StringLookup(max_tokens=max_tokens)\n",
        "  else:\n",
        "    index = IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a Dataset that only yields our feature\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Create a Discretization for our integer indices.\n",
        "  encoder = CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply one-hot encoding to our indices and return this feature\n",
        "  return lambda feature: encoder(index(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJfdy1DFsxO"
      },
      "source": [
        "The TensorFlow 2.0 Documentation has more details on [StringLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup), [IntegerLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup) and [CategoryEncoding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PLPkq4rZlF2",
        "outputId": "6644e33d-7a3f-4e62-c242-25caa9e1dc92"
      },
      "outputs": [],
      "source": [
        "index = StringLookup(max_tokens=None)\n",
        "feature_ds = train_ds.map(lambda x, y: x['embark_town'])\n",
        "index.adapt(feature_ds)\n",
        "\n",
        "print(f'vocabulary: {index.get_vocabulary()}')\n",
        "print(f'vocabulary size: {index.vocabulary_size()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "CLPr5QwJZx1h",
        "outputId": "8a046acf-ad44-4bed-b157-973971b1b5ef"
      },
      "outputs": [],
      "source": [
        "index.oov_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LvWeq7b30yr"
      },
      "source": [
        "Let's take a look at a batch of 3 entries. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPdk6WMHfv1v",
        "outputId": "d238413b-ad69-4c80-d2c0-b409546f06b7"
      },
      "outputs": [],
      "source": [
        "embark_town_column = train_features['embark_town']\n",
        "embark_town_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2t2ff9K8PcT",
        "outputId": "f046370b-3619-4c62-985d-52edd8a7538c"
      },
      "outputs": [],
      "source": [
        "categorical_layer = get_category_encoding_layer('embark_town', train_ds, 'string')\n",
        "categorical_layer(embark_town_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8LMv-6tjB53"
      },
      "source": [
        "### Creating a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wVwChZii8Sz"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFHfo4Q_z3X"
      },
      "source": [
        "- Next let's take a look at our numeric and categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjh_MrwtjP4x"
      },
      "outputs": [],
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numeric features.\n",
        "numeric_columns = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "for column_name in numeric_columns:\n",
        "    numeric_column = tf.keras.Input(shape=(1,), name=column_name)\n",
        "    normalization_layer = get_normalization_layer(column_name, train_ds)\n",
        "    encoded_numeric_column = normalization_layer(numeric_column)\n",
        "    all_inputs.append(numeric_column)\n",
        "    encoded_features.append(encoded_numeric_column)\n",
        "\n",
        "# Categorical features encoded as string.\n",
        "categorical_columns = ['sex', 'class', 'embark_town', 'deck', 'alone']\n",
        "for column_name in categorical_columns:\n",
        "    categorical_column = tf.keras.Input(shape=(1,), name=column_name, dtype='string')\n",
        "    encoding_layer = get_category_encoding_layer(column_name, train_ds, dtype='string', max_tokens=5)\n",
        "    encoded_categorical_column = encoding_layer(categorical_column)\n",
        "    all_inputs.append(categorical_column)\n",
        "    encoded_features.append(encoded_categorical_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYa6YYvlir83"
      },
      "source": [
        "Let's take a look at the list all_inputs to see what we have. You can see these are the different columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlI-kce-eJBr",
        "outputId": "e6e0634d-6f75-495a-8aab-7e83d18eedab"
      },
      "outputs": [],
      "source": [
        "all_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6xywgIgjA3-"
      },
      "source": [
        "The encoded_features is all of the layers that have been normalized for numeric values and have category encoding for categorical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2im054Ceagr",
        "outputId": "c1f33a21-b1a6-40f3-8cfb-3bc891503af5"
      },
      "outputs": [],
      "source": [
        "encoded_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaV4pQ1CnO9-"
      },
      "source": [
        "## Train and evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVh9afkUo890"
      },
      "source": [
        "### Design Model\n",
        "- Working with tabular data requires more preprocessing than imagery\n",
        "- However the model design is pretty similar to Fashion-MNIST\n",
        "- Some differences\n",
        "    - Don't need to flatten cause we're not using grid values\n",
        "    - Uses a dropout to prevent overfitting\n",
        "    - Final output is only a single node\n",
        "    - Switched to `BinaryCrossentropy` for loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v37OLRrjPu-"
      },
      "outputs": [],
      "source": [
        "#compile\n",
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(all_features)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "z7HR2BlOoD7C",
        "outputId": "bd46eed6-a75d-4c33-ff3d-513738047e6e"
      },
      "outputs": [],
      "source": [
        "# rankdir='LR' is used to make the graph horizontal.\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RauLatYIpB-O"
      },
      "source": [
        "### Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OonIVsfVpFWQ",
        "outputId": "2f1412cb-d51a-4e39-f785-ee3ca31cc2df"
      },
      "outputs": [],
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ix6ICW3pLgT",
        "outputId": "8b868af1-fc85-4ed1-d15b-b17ef2702663"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print('Accuracy', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4XP-EVBBBbv",
        "outputId": "976a849e-5b38-4e63-9cd6-ffd75b8beace"
      },
      "outputs": [],
      "source": [
        "model.save('classifier')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF2.0_working_with_tabular_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
